{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b06ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: [784, 300, 100, 10]\n",
      "EPOCH: none, mis-classified: 53545, percent: 0.8924166666666666\n",
      "EPOCH: 0, mis-classified: 4150, percent: 0.06916666666666667\n",
      "EPOCH: 1, mis-classified: 2670, percent: 0.0445\n",
      "EPOCH: 2, mis-classified: 2087, percent: 0.03478333333333333\n",
      "EPOCH: 3, mis-classified: 1614, percent: 0.0269\n",
      "EPOCH: 4, mis-classified: 1265, percent: 0.021083333333333332\n",
      "misclassified percent testSet: 0.0373\n"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np, math, random, pickle\n",
    "\n",
    "def p_net(A, x, w_list, b_list):\n",
    "    new_A = np.vectorize(A)\n",
    "    new_round = np.vectorize(round)\n",
    "    a = x\n",
    "    for layer in range(1, len(w_list)):\n",
    "        a = new_A(a@w_list[layer] + b_list[layer])\n",
    "    return a\n",
    "\n",
    "def p_net2(A, x, w_list, b_list):\n",
    "    new_A = np.vectorize(A)\n",
    "    new_round = np.vectorize(round)\n",
    "    new_zero = np.vectorize(zero)\n",
    "    a = x\n",
    "    for layer in range(1, len(w_list)):\n",
    "        a = new_A(a@w_list[layer] + b_list[layer])\n",
    "    maxi = max(max(a))\n",
    "    return new_zero(a, maxi)\n",
    "    \n",
    "    \n",
    "def zero(num, maxi):\n",
    "    return 0 if num < maxi else 1\n",
    "\n",
    "def sigmoid(num):\n",
    "    return 1 / (1 + np.exp(-num))\n",
    "\n",
    "def dsigmoid(num):\n",
    "    return sigmoid(num) * (1 - sigmoid(num))\n",
    "\n",
    "def error(result, output):\n",
    "    return 0.5 * np.linalg.norm(output - result)**2\n",
    "\n",
    "def train2(trainSet, epoch, w_list, b_list, A, rate):\n",
    "    a_list, delta_list, dot_list = list(), list(), list()\n",
    "    N = len(w_list)\n",
    "    new_a = np.vectorize(sigmoid)\n",
    "    new_da = np.vectorize(dsigmoid)\n",
    "    lastError = None\n",
    "    error2 = None\n",
    "    wrong = 0\n",
    "    for j in trainSet:\n",
    "        if not np.array_equal(j[1], p_net2(sigmoid, j[0], w_list, b_list)):\n",
    "            wrong += 1\n",
    "    print(\"EPOCH: none, mis-classified: %s, percent: %s\" % (wrong, wrong/len(trainSet)))\n",
    "    for i in range(epoch):\n",
    "        for x, y in trainSet:\n",
    "            a_list, delta_list, dot_list = list(), list(), list()\n",
    "            a_list.append(x)\n",
    "            delta_list.append(\"\")\n",
    "            dot_list.append(0)\n",
    "            for layer in range(1, N):\n",
    "                dot = a_list[layer-1]@w_list[layer] + b_list[layer]\n",
    "                dot_list.append(dot)\n",
    "                a_list.append(new_a(dot))\n",
    "                delta_list.append(\"\")\n",
    "            delta_list[N-1] = new_da(dot_list[N-1]) * (y - a_list[N-1]) \n",
    "            for layer in range(N-2, 0, -1):\n",
    "                delta_list[layer] = new_da(dot_list[layer]) * (delta_list[layer+1] @ w_list[layer+1].transpose())\n",
    "            for layer in range(1, N):\n",
    "                b_list[layer] = b_list[layer] + rate * delta_list[layer]\n",
    "                w_list[layer] = w_list[layer] + rate * (a_list[layer-1].transpose() @ delta_list[layer])\n",
    "        # after epoch finishes, find number of mis-classified points\n",
    "        wrong = 0\n",
    "        for j in trainSet:\n",
    "            if not np.array_equal(j[1], p_net2(sigmoid, j[0], w_list, b_list)):\n",
    "                wrong += 1\n",
    "        print(\"EPOCH: %s, mis-classified: %s, percent: %s\" % (i, wrong, wrong/len(trainSet)))\n",
    "        pickle.dump(w_list, open(\"w_list.txt\", \"wb\"))\n",
    "        pickle.dump(b_list, open(\"b_list.txt\", \"wb\"))\n",
    "    return w_list, b_list\n",
    "\n",
    "def generate(network):\n",
    "    w_list, b_list = list(), list()\n",
    "    # first is the w_list\n",
    "    w_list.append(None)\n",
    "    b_list.append(None)\n",
    "    for i in range(len(network)-1):\n",
    "        w_list.append(2 * np.random.rand(network[i], network[i+1]) - 1)\n",
    "    # now the b_list\n",
    "    for i in range(1, len(network)):\n",
    "        b_list.append(2 * np.random.rand(1, network[i]) - 1)\n",
    "    return w_list, b_list\n",
    "\n",
    "\n",
    "train = pickle.load(open(\"trainSet.txt\", \"rb\"))\n",
    "print(\"Network: [784, 300, 100, 10]\")\n",
    "w_list, b_list = pickle.load(open(\"w_list.txt\", \"rb\")), pickle.load(open(\"b_list.txt\", \"rb\"))\n",
    "pickle.dump(w_list, open(\"best_w_list.txt\", \"wb\"))\n",
    "pickle.dump(b_list, open(\"best_b_list.txt\", \"wb\"))\n",
    "\n",
    "\n",
    "w_list, b_list = generate([784, 300, 100, 10])\n",
    "w_list, b_list = train2(train, 5, w_list, b_list, sigmoid, 0.15)\n",
    "\n",
    "\n",
    "### TESTING PART\n",
    "test = pickle.load(open(\"testSet.txt\", \"rb\"))\n",
    "w_list = pickle.load(open(\"w_list.txt\", \"rb\"))\n",
    "b_list = pickle.load(open(\"b_list.txt\", \"rb\"))\n",
    "\n",
    "wrong = 0\n",
    "errorSum = 0\n",
    "for i in test:\n",
    "    result = p_net2(sigmoid, i[0], w_list, b_list)\n",
    "    if not np.array_equal(i[1], result):\n",
    "        wrong += 1\n",
    "    errorSum += error(result, i[1])    \n",
    "print(\"misclassified percent testSet: %s\" % (wrong / len(test),))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d85c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
